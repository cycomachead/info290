{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4- Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment uses 2012 data obtained from the Federal Election Commission on contributions to candidates from committees. The data dictionary is available at http://www.fec.gov/finance/disclosure/metadata/DataDictionaryContributionstoCandidates.shtml. The file we've given you has been subset to 10,000 randomly sampled rows, wth some columns removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "from collections import Counter, defaultdict\n",
    "from itertools import combinations \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction import DictVectorizer #to turn categorial variables into numeric arrays\n",
    "from sklearn import preprocessing #to transform the feature labels\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CMTE_ID</th>\n",
       "      <th>AMNDT_IND</th>\n",
       "      <th>RPT_TP</th>\n",
       "      <th>ENTITY_TP</th>\n",
       "      <th>NAME</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>ZIP_CODE</th>\n",
       "      <th>TRANSACTION_DT</th>\n",
       "      <th>TRANSACTION_AMT</th>\n",
       "      <th>CAND_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> C90011156</td>\n",
       "      <td> N</td>\n",
       "      <td> Q3</td>\n",
       "      <td> IND</td>\n",
       "      <td> ROULAND, PRESTON</td>\n",
       "      <td> CLEVELAND</td>\n",
       "      <td> OH</td>\n",
       "      <td> 44135</td>\n",
       "      <td>  9182012</td>\n",
       "      <td> 26</td>\n",
       "      <td>  Obama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> C90011156</td>\n",
       "      <td> N</td>\n",
       "      <td> Q3</td>\n",
       "      <td> IND</td>\n",
       "      <td>   DANFORD, KAYLA</td>\n",
       "      <td>    OXFORD</td>\n",
       "      <td> OH</td>\n",
       "      <td> 45056</td>\n",
       "      <td>  9242012</td>\n",
       "      <td> 17</td>\n",
       "      <td>  Obama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> C90011156</td>\n",
       "      <td> N</td>\n",
       "      <td> YE</td>\n",
       "      <td> IND</td>\n",
       "      <td>   CLARK, BARBARA</td>\n",
       "      <td> WHITEHALL</td>\n",
       "      <td> OH</td>\n",
       "      <td> 43213</td>\n",
       "      <td> 10032012</td>\n",
       "      <td> 18</td>\n",
       "      <td> Romney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> C90011156</td>\n",
       "      <td> N</td>\n",
       "      <td> YE</td>\n",
       "      <td> ORG</td>\n",
       "      <td>  JENNIFER JANNON</td>\n",
       "      <td>   DORMONT</td>\n",
       "      <td> PA</td>\n",
       "      <td> 15216</td>\n",
       "      <td> 10262012</td>\n",
       "      <td> 11</td>\n",
       "      <td>  Obama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> C90011156</td>\n",
       "      <td> N</td>\n",
       "      <td> YE</td>\n",
       "      <td> IND</td>\n",
       "      <td>    ARNDI, PHILIP</td>\n",
       "      <td>    BOSTON</td>\n",
       "      <td> MA</td>\n",
       "      <td>  2115</td>\n",
       "      <td> 11062012</td>\n",
       "      <td> 57</td>\n",
       "      <td>  Obama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     CMTE_ID AMNDT_IND RPT_TP ENTITY_TP              NAME       CITY STATE  \\\n",
       "0  C90011156         N     Q3       IND  ROULAND, PRESTON  CLEVELAND    OH   \n",
       "1  C90011156         N     Q3       IND    DANFORD, KAYLA     OXFORD    OH   \n",
       "2  C90011156         N     YE       IND    CLARK, BARBARA  WHITEHALL    OH   \n",
       "3  C90011156         N     YE       ORG   JENNIFER JANNON    DORMONT    PA   \n",
       "4  C90011156         N     YE       IND     ARNDI, PHILIP     BOSTON    MA   \n",
       "\n",
       "  ZIP_CODE TRANSACTION_DT  TRANSACTION_AMT CAND_ID  \n",
       "0    44135        9182012               26   Obama  \n",
       "1    45056        9242012               17   Obama  \n",
       "2    43213       10032012               18  Romney  \n",
       "3    15216       10262012               11   Obama  \n",
       "4     2115       11062012               57   Obama  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('lab4_candidate_contributions.csv')\n",
    "\n",
    "#convert zip code and transaction date from floats to strings (since we wnat to treat them as categorical)\n",
    "df.ZIP_CODE = df.ZIP_CODE.astype('int').astype('str')\n",
    "df.TRANSACTION_DT = df.TRANSACTION_DT.astype('int').astype('str')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Gini Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Question 1: How many rows are there in the dataset for Obama? For Romney? **\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obama: 5761, Romney: 4239\n"
     ]
    }
   ],
   "source": [
    "obama = 0\n",
    "romney = 0\n",
    "for i in range(df.CAND_ID.size):\n",
    "    if df.CAND_ID.get_value(i) == \"Obama\":\n",
    "        obama += 1\n",
    "    else:\n",
    "        romney += 1\n",
    "print(\"Obama: %d, Romney: %d\"%(obama, romney))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2: What is the Gini Index of the this dataset, using Romney and Obama as the target classes?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gini index: 0.488418\n"
     ]
    }
   ],
   "source": [
    "def gini(D):\n",
    "    obama = sum(D.CAND_ID == \"Obama\")\n",
    "    romney = sum(D.CAND_ID == \"Romney\")\n",
    "    total = obama+romney\n",
    "    return 1-((obama/total)**2+(romney/total)**2)\n",
    "    \n",
    "print(\"gini index: %f\"%gini(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Split of a Numeric Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split after: 8040, gini score: 0.488082, gini reduced by: 0.000336, Obama below: 4581, Obama above: 1180, Romney below: 3460, Romney above: 779\n"
     ]
    }
   ],
   "source": [
    "sortd = df.sort(columns=\"TRANSACTION_AMT\")\n",
    "mingini = 1\n",
    "mini = 0\n",
    "ob1 = 0\n",
    "ob2 = sum(df.CAND_ID == \"Obama\")\n",
    "ro1 = 0\n",
    "ro2 = sum(df.CAND_ID == \"Romney\")\n",
    "total = ob2+ro2\n",
    "for i in range(df.CAND_ID.size-1):\n",
    "    if sortd.CAND_ID.get_value(i) == \"Obama\":\n",
    "        ob1 += 1\n",
    "        ob2 -= 1\n",
    "    else:\n",
    "        ro1 += 1\n",
    "        ro2 -= 1\n",
    "    low = df.TRANSACTION_AMT.get_value(i)\n",
    "    high = df.TRANSACTION_AMT.get_value(i+1)\n",
    "    if low != high:\n",
    "        tot1 = ob1+ro1\n",
    "        tot2 = ob2+ro2\n",
    "        gini1 = 1-((ob1/tot1)**2+(ro1/tot1)**2)\n",
    "        gini2 = 1-((ob2/tot2)**2+(ro2/tot2)**2)\n",
    "        ginit = gini1*((ob1+ro1)/total) + gini2*((ob2+ro2)/total)\n",
    "        if ginit < mingini:\n",
    "            mini = i\n",
    "            mingini = ginit\n",
    "            minob1 = ob1\n",
    "            minob2 = ob2\n",
    "            minro1 = ro1\n",
    "            minro2 = ro2\n",
    "\n",
    "print(\"split after: %d, gini score: %f, gini reduced by: %f, Obama below: %d, Obama above: %d, Romney below: %d, Romney above: %d\"%(mini, mingini, (gini(df)-mingini), minob1, minob2, minro1, minro2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3: What is the best split point of the TRANSACTION_AMT feature. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8040"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4: What is the Gini Index of this best split?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48808188000763558"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mingini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5: How much does this partitioning reduce the Gini Index over that of the overall dataset?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00033569999236454651"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(gini(df)-mingini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6: How many Romney rows are below your best split point? Obama rows?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Romney Rows:  3460\n",
      "Obama Rows: 4581\n"
     ]
    }
   ],
   "source": [
    "print(\"Romney Rows: \", minro1)\n",
    "print(\"Obama Rows:\", minob1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7: How many Romney rows are above your best split point? Obama rows?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that, to calculate the best split of this numeric field, you'll need to order your data by TRANSACTION AMT, then consider the midpoint between each pair of consecutive transaction amounts as a potential split point, then calculate the Gini Index for that partitioning. You'll want to keep track of the best split point and its Gini Index (remember that you are trying to minimize the Gini Index). \n",
    "\n",
    "There are a lot of ways to do this. Some are very fast, others very slow. One tip to make this run quickly is, as you consecutively step through the data and calculate the Gini Index of each possible split point, keep a running total of the number of rows for each candidate that are located above and below the split point. \n",
    "\n",
    "Some Python tips: \n",
    "\n",
    "* Counter(), from the collections module, is a special dictionary for counting values of a key\n",
    "* zip() lets you concatenate lists into a list of tuples (for example, if we have a list of the candidates and a list of transaction amounts, zip(candidate_list, transaction_amount) would give us a list of (candidate, transaction amount) pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split after: 8040, gini score: 0.488082, gini reduced by: 0.000336, Obama below: 4581, Obama above: 1180, Romney below: 3460, Romney above: 779\n"
     ]
    }
   ],
   "source": [
    "sortd = df.sort(columns=\"TRANSACTION_AMT\")\n",
    "mingini = 1\n",
    "mini = 0\n",
    "ob1 = 0\n",
    "ob2 = sum(df.CAND_ID == \"Obama\")\n",
    "ro1 = 0\n",
    "ro2 = sum(df.CAND_ID == \"Romney\")\n",
    "total = ob2+ro2\n",
    "for i in range(df.CAND_ID.size-1):\n",
    "    if sortd.CAND_ID.get_value(i) == \"Obama\":\n",
    "        ob1 += 1\n",
    "        ob2 -= 1\n",
    "    else:\n",
    "        ro1 += 1\n",
    "        ro2 -= 1\n",
    "    low = df.TRANSACTION_AMT.get_value(i)\n",
    "    high = df.TRANSACTION_AMT.get_value(i+1)\n",
    "    if low != high:\n",
    "        tot1 = ob1+ro1\n",
    "        tot2 = ob2+ro2\n",
    "        gini1 = 1-((ob1/tot1)**2+(ro1/tot1)**2)\n",
    "        gini2 = 1-((ob2/tot2)**2+(ro2/tot2)**2)\n",
    "        ginit = gini1*((ob1+ro1)/total) + gini2*((ob2+ro2)/total)\n",
    "        if ginit < mingini:\n",
    "            mini = i\n",
    "            mingini = ginit\n",
    "            minob1 = ob1\n",
    "            minob2 = ob2\n",
    "            minro1 = ro1\n",
    "            minro2 = ro2\n",
    "\n",
    "print(\"split after: %d, gini score: %f, gini reduced by: %f, Obama below: %d, Obama above: %d, Romney below: %d, Romney above: %d\"%(mini, mingini, (gini(df)-mingini), minob1, minob2, minro1, minro2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Split of a Categorial Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "# question 8\n",
    "entity_vals = pd.unique(df[\"ENTITY_TP\"])\n",
    "combinations = functools.reduce(lambda x,y: x+y, [list(itertools.combinations(entity_vals, r)) for r in range(1, len(entity_vals)//2 + 1)])\n",
    "\n",
    "# question 9\n",
    "mingini = 1\n",
    "mincomb = None\n",
    "for comb in combinations:\n",
    "    indices = df[\"ENTITY_TP\"].isin(comb)\n",
    "    split1 = df.loc[indices,:]\n",
    "    split2 = df.loc[~indices,:]\n",
    "    cur_gini = (len(split1) * gini(split1) + len(split2) * gini(split2)) / len(df)\n",
    "    if cur_gini < mingini:\n",
    "        mingini = cur_gini\n",
    "        mincomb = comb\n",
    "        min_split1 = split1\n",
    "        min_split2 = split2\n",
    "    \n",
    "    #print \"%d, %d\"%(len(split1), len(split2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 8: How many possible splits are there of the ENTITY_TP feature?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combinations)\n",
    "# (2**7 - 2) / 2 (because we optimize by throwing out half)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 9: Which split of ENTITY_TP best splits the Obama and Romney rows, as measured by the Gini Index?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('CCM', 'COM', 'CAN')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# question 9\n",
    "mincomb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 10: What is the Gini Index of this best split?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48314520835547992"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# question 10\n",
    "mingini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 11: How much does this partitioning reduce the Gini Index over that of the overall data set?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0052723716445202129"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# question 11\n",
    "gini(df) - mingini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 12: How many Romney rows and Obama rows are in your first partition? How many Romney rows and Obama rows are in your second partition?**"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 16,
=======
   "execution_count": 64,
>>>>>>> 61e28efd2850992f56e5c6bffeb23525aaf920f5
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Romney: 147, Obama: 37\n",
      "Romney: 4092, Obama: 5724\n"
     ]
    }
   ],
   "source": [
    "# question 12\n",
    "print(\"Romney: %s, Obama: %s\"%(sum(min_split1.CAND_ID == \"Romney\"), sum(min_split1.CAND_ID == \"Obama\")))\n",
    "print(\"Romney: %s, Obama: %s\"%(sum(min_split2.CAND_ID == \"Romney\"), sum(min_split2.CAND_ID == \"Obama\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you will be partitioning the original dataset (as opposed to further partitioning the transaction amount partitions from the previous set of questions).\n",
    "\n",
    "Python tip: the combinations function of the itertools module allows you to enumerate combinations of a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 13: Using all of the features in the original dataframe read in at the top of this notebook, train a decision tree classifier that has a depth of three (including the root node and leaf nodes). What is the accuracy of this classifier on the training data?**"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 19,
=======
   "execution_count": 65,
>>>>>>> 61e28efd2850992f56e5c6bffeb23525aaf920f5
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import sample\n",
    "def trainingSample(n, size):\n",
    "    rows = sample(range(n), size)\n",
    "    return rows\n",
    "\n",
    "def separateRows(training_rows, data):\n",
    "    \"\"\" Return (training set, prediction set) with n% of rows in training set\"\"\"\n",
    "    training = data.ix[training_rows]\n",
    "    prediction = data.drop(training_rows)\n",
    "    return (training, prediction)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 20,
=======
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "classifier = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=3, min_samples_split=2, min_samples_leaf=1, max_features=None, random_state=None, min_density=None, compute_importances=None, max_leaf_nodes=None)\n",
    "df_new = df.copy()\n",
    "df_new.TRANSACTION_DT = df_new.TRANSACTION_DT.apply(lambda x: x if len(x) == 8 else \"0\" + x)\n",
    "df_new.TRANSACTION_DT = df_new.TRANSACTION_DT.apply(lambda x: datetime.strptime(x, \"%m%d%Y\").toordinal())\n",
    "\n",
    "CAND_ID = df_new.CAND_ID\n",
    "X = df_new.drop(\"CAND_ID\", axis = 1)\n",
    "\n",
    "vec = DictVectorizer()\n",
    "X = pd.DataFrame(vec.fit_transform(X.to_dict(\"records\")).toarray())\n",
    "X.columns = vec.get_feature_names()\n",
    "\n",
    "train_size = 0.75\n",
    "training_rows = trainingSample(X.shape[0], int(train_size * X.shape[0]))\n",
    "train_rows, pred_rows = separateRows(training_rows, X)\n",
    "train_Y, pred_Y = separateRows(training_rows, CAND_ID)\n",
    "\n",
    "\n",
    "train_Y = train_Y == 'Obama'\n",
    "train_Y = train_Y.astype(int)\n",
    "pred_Y = pred_Y == 'Obama'\n",
    "pred_Y = pred_Y.astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = classifier.fit(train_rows, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
>>>>>>> 61e28efd2850992f56e5c6bffeb23525aaf920f5
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
<<<<<<< HEAD
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-b8e95f35c911>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_rows\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCAND_ID\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Obama'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_mask, X_argsorted, check_input, sample_weight)\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[1;31m# Convert data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"dense\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[1;31m# Determine output settings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_arrays\u001b[1;34m(*arrays, **options)\u001b[0m\n\u001b[0;32m    279\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mascontiguousarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 281\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    282\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nans\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m                     \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/numpy/core/numeric.pyc\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \"\"\"\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a number"
     ]
=======
     "data": {
      "text/plain": [
       "0.57906666666666662"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
>>>>>>> 61e28efd2850992f56e5c6bffeb23525aaf920f5
    }
   ],
   "source": [
    "classifier.score(train_rows, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56720000000000004"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(pred_rows, pred_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 14: Export your decision tree to graphviz. Please submit a png file of this graphic to bcourses. In your write-up, write down the interpretation of the rule at each node (for example, 'Root node: rows from state AL go the the left, rows from all other states go to the right. Left child of root node: ... etc**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.externals.six import StringIO\n",
    "with open(\"obama_romney.dot\", 'w') as f:\n",
    "    f = sklearn.tree.export_graphviz(clf, out_file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRANSACTION_DT\n",
      "CITY=AKRON\n",
      "CMTE_ID=C90011156\n",
      "CMTE_ID=C00521013\n",
      "ENTITY_TP=IND\n",
      "STATE=NC\n"
     ]
    }
   ],
   "source": [
    "print(train_rows.columns[2768])\n",
    "print(train_rows.columns[7])\n",
    "print(train_rows.columns[745])\n",
    "print(train_rows.columns[706])\n",
    "print(train_rows.columns[810])\n",
    "print(train_rows.columns[2745])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The topmost split depends on the date of the contribution. The next highest are whether a contribution was from Akron, and whether CMTE_ID equals C90011156 (which we think has to do with who the contributor is). The final row splits on whether CMTE_ID equals C00521013, whether the donor is an individual, and whether the state is North Carolina."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 15: For each of your leaf nodes, specify the percentage of Obama rows in that node (out of the total number of rows at that node).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.526161895968\n",
      "1.0\n",
      "0.572519083969\n",
      "0.985507246377\n",
      "0.955380577428\n",
      "0.5625\n"
     ]
    }
   ],
   "source": [
    "print(3419 / (3079 + 3419))\n",
    "print(135 / (0 + 135))\n",
    "print(75 / (56 + 75))\n",
    "print(68/ (1 + 68))\n",
    "print(364 / (17 + 364))\n",
    "print(9 / (7 + 9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See this notebook for the basics of training a decision tree in scikit-learn and exporting the outputs to view in graphviz: http://nbviewer.ipython.org/gist/tebarkley/b68c04d9b31e64ce6023\n",
    "\n",
    "Scikit-learn classifiers require class labels and features to be in numeric arrays. As such, you will need to turn your categorical features into numeric arrays using DictVectorizer. This is a helpful notebook for understanding how to do this: http://nbviewer.ipython.org/gist/sarguido/7423289. You can turn a pandas dataframe of features into a dictionary of the form needed by DictVectorizer by using df.to_dict('records'). Make sure you remove the class label first (in this case, CAND_ID). If you use the class label as a feature, your classifier will have a training accuracy of 100%! The example notebook link also shows how to turn your class labels into a numeric array using sklearn.preprocessing.LabelEncoder().\n",
    "\n",
    "We already did this for you at the top of the notebook, but before you convert your features into numeric arrays, you should always make sure they are of the correct type (ie zip code should be a string, not a float, because it is a categorical variable). \n",
    "\n",
    "Question 14 asks you to interpret the rules at each decision tree node using the graphviz output. The graphviz output looks cryptic (ie it might tell you that X[1014] < 0.5 is the best split for a particular node. To figure out what feature that corresponds to, use the .get_feature_names() function of your DictVectorizer object. If that returns something like 'CITY=PHOENIX', then you know that the left child of the node contains rows not in Phoenix ('CITY=PHOENIX' ==0) and the right child of the node contains rows in Phoenix ('CITY=PHOENIX' == 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "gist_id": "0945553f802dad1bfa88",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
