{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Per-Review Analysis\n",
    "\n",
    "----\n",
    "> Note: All the paths are relative to the location of this file in `project/` !\n",
    "> The following folders are expected:\n",
    "> * `data/`\n",
    "> * `processed/` , `processed/word-freq-by-review/` , `processed/pandas/`\n",
    "\n",
    "## This file is attempting to do Linear Regression on a per-review level to predict individual beers and styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "from __future__ import print_function\n",
    "from pandas import *\n",
    "from sklearn import linear_model\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "import sklearn\n",
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# Constants\n",
    "REVIEWS_CSV = 'processed/word-freq-by-review/'\n",
    "ALL_WORDS_FILE = 'processed/all_sorted'\n",
    "DATA_DIR = 'processed/pandas/'\n",
    "\n",
    "# Word Filtering\n",
    "SMALL_A = 97\n",
    "SMALL_Z = SMALL_A + 26\n",
    "\n",
    "def is_worth_keeping(word):\n",
    "    word = word.lower()\n",
    "    word = word.strip()\n",
    "    if len(word) >= 3:\n",
    "        for c in word:\n",
    "            if ord(c) < SMALL_A or ord(c) > SMALL_Z:\n",
    "                return False\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def walkDir(base):\n",
    "    \"\"\"\n",
    "    Generate a single list of all the files in a directory\n",
    "    DFS, and include the full path relative to base.\n",
    "\n",
    "    \"\"\"\n",
    "    files = list(os.walk(base))\n",
    "    files = files[1:]\n",
    "    paths = []\n",
    "    for group in files:\n",
    "        for f in group[2]:\n",
    "            paths.append(group[0] + '/' + f)\n",
    "    paths = list(filter(lambda x: x.find('.txt') == -1, paths))\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Only refresh this cell when needed!!!\n",
    "# --------------------------------------\n",
    "ALL_WORDS = []\n",
    "# Map an id to an array for row numbers\n",
    "TRAINING_ROWS = {}\n",
    "TEST_ROWS = {}\n",
    "# Style: [beer ids]\n",
    "STYLES = defaultdict(list)\n",
    "# data...\n",
    "DATA = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104 styles\n"
     ]
    }
   ],
   "source": [
    "ALL_STYLES = []\n",
    "for f in os.listdir('data'):\n",
    "    if f != '.DS_Store' and f != 'all_beers.txt':\n",
    "        ALL_STYLES.append(f)\n",
    "\n",
    "print(\"%d styles\" % len(ALL_STYLES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: 259005 total words\n",
      "Found: 232090 usable words\n"
     ]
    }
   ],
   "source": [
    "# Read In Files\n",
    "with open(ALL_WORDS_FILE, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    print('Found:', len(lines), 'total words')\n",
    "    ALL_WORDS = [word for word in lines if is_worth_keeping(word)]    \n",
    "print('Found:', len(ALL_WORDS), 'usable words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unsupported pickle protocol: 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-d18eb8ddc69f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mipa_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'processed/pandas/American_IPA.pkl'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mipa_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/io/pickle.pyc\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtry_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mPY3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/io/pickle.pyc\u001b[0m in \u001b[0;36mtry_read\u001b[0;34m(path, encoding)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/compat/pickle_compat.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(fh, encoding, compat, is_verbose)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_verbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_verbose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    856\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 858\u001b[0;31m                 \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    859\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mload_proto\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0mproto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mproto\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 886\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"unsupported pickle protocol: %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    887\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mPROTO\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_proto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: unsupported pickle protocol: 4"
     ]
    }
   ],
   "source": [
    "# testing ground! \n",
    "\n",
    "ipa_data = 'processed/pandas/American_IPA.pkl'\n",
    "data = read_pickle(ipa_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a linear regression\n",
    "from sklearn import linear_model\n",
    "\n",
    "logreg = linear_model.LogisticRegression(C=1e5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# IGNORE THIS CODE FOR NOW...\n",
    "# ----------------------------\n",
    "\n",
    "paths = walkDir(REVIEWS_CSV)\n",
    "errors = []\n",
    "for p in paths:\n",
    "    parts = p.split('/')\n",
    "    style = parts[2]\n",
    "    id = parts[3]\n",
    "    # Setup\n",
    "    STYLES[style] += [ id ] # contains an array of file ids\n",
    "    TRAINING_ROWS[id] = []\n",
    "    TEST_ROWS[id] = []\n",
    "    #raw_data = ''\n",
    "    #with open(p, 'r+') as f:\n",
    "    #    raw_data = f.read()\n",
    "    if id not in DATA:\n",
    "        try:\n",
    "            csv_data = read_csv(p, header=0)\n",
    "            # Cleanup bad first columns...\n",
    "            del csv_data[csv_data.icol(0).name]\n",
    "            DATA[id] = csv_data\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            errors.append(p)\n",
    "            print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
